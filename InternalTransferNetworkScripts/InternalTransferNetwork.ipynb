{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro/Imports\n",
    "This notebook pulls together pieces to complete a cross validation analysis of the two tiered classification method. The end result is a 93% classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import OtolithAnalysis as oa\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim_fold = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This order was printed and copied from the AWS training script\n",
    "# where it was generated randomly (with a seed of 1)\n",
    "# cvorder = [14,98,75,16,131,56,141,44,29,120,94,5,102,51,78,42,\n",
    "#            92,66,31,35,90,84,77,40,125,99,33,19,73,146,91,135,\n",
    "#            69,128,114,48,53,28,54,108,112,17,119,103,58,118,18,\n",
    "#            4,45,59,39,36,117,139,107,132,126,85,122,95,11,113,\n",
    "#            123,12,2,104,6,127,110,65,55,144,138,46,62,74,116,\n",
    "#            93,100,89,10,34,32,124,38,83,111,149,27,23,67,9,130,\n",
    "#            97,105,145,87,148,109,64,15,82,41,80,52,26,76,43,24,\n",
    "#            136,121,143,49,21,70,3,142,30,147,106,47,115,13,88,\n",
    "#            8,81,60,0,1,57,22,61,63,7,86,96,68,50,101,20,25,134,\n",
    "#            71,129,79,133,137,72,140,37]\n",
    "# pickle.dump(cvorder,open('crossval_order.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir0 = 'ClassifierSampleSelection'\n",
    "subdir1 = 'Samples'\n",
    "subdir2 = 'Scores'\n",
    "subdir3 = 'Score_Tables'\n",
    "dir1 = 'ClassifierSampleSelection50'\n",
    "pstr = '2019_08_18_ClassifierNetworkForSelection_'\n",
    "destdir = 'ClassifierSampleSelectionCombined'\n",
    "# os.mkdir(destdir)\n",
    "# os.mkdir(os.path.join(destdir, subdir1))\n",
    "# os.mkdir(os.path.join(destdir, subdir2))\n",
    "# os.mkdir(os.path.join(destdir, subdir3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_lists(ftype, subdir, ind):\n",
    "#     with open(os.path.join(dir0, subdir, pstr + \n",
    "#                        ftype + '_' + str(ind) + '.p'), 'rb') as f:\n",
    "#         samp = pickle.load(f)\n",
    "#     with open(dir1 + '/' + pstr + ftype + '50_' + str(ind) + '.p', 'rb') as f:\n",
    "#         samp50 = pickle.load(f)\n",
    "#     samp.extend(samp50)\n",
    "#     with open(os.path.join(destdir, subdir, ftype + '_' + str(ind) + '.p'), 'wb') as f:\n",
    "#         pickle.dump(samp, f)\n",
    "# for ind in range(10):\n",
    "#     combine_lists('SmoothedSamples', subdir1, ind)\n",
    "#     combine_lists('Scores', subdir2, ind)\n",
    "#     combine_lists('ScoreTable', subdir3, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transfer_module(model):\n",
    "    model2 = keras.Sequential()\n",
    "    model2.add(keras.layers.Conv1D(256, 3, weights=model.layers[0].get_weights(), activation=tf.nn.relu))\n",
    "    model2.add(keras.layers.Conv1D(128, 9, activation=tf.nn.relu, weights=model.layers[1].get_weights()))\n",
    "    model2.add(keras.layers.Flatten())\n",
    "    model2.add(keras.layers.Dense(256, activation=tf.nn.relu, weights=model.layers[3].get_weights()))\n",
    "    return model2\n",
    "\n",
    "def make_none_marked_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crossval_order.p', 'rb') as f:\n",
    "    cvorder = np.array(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently evaluating image number 0\n",
      "Currently evaluating image number 5\n",
      "Currently evaluating image number 10\n",
      "Currently evaluating image number 15\n",
      "Currently evaluating image number 20\n",
      "Currently evaluating image number 25\n"
     ]
    }
   ],
   "source": [
    "# extra_none = []\n",
    "# for im_ind in range(30):\n",
    "#     if im_ind % 5 == 0:\n",
    "#         print(\"Currently evaluating image number {}\".format(im_ind))\n",
    "#     for s_name in os.listdir(none_fbase + '/' + str(im_ind)):\n",
    "#         extra_none.append([])\n",
    "#         with open(os.path.join(none_fbase, str(im_ind), s_name), 'rb') as f:\n",
    "#             s = pickle.load(f)\n",
    "#         extra_none[-1].append(oa.finder_network.fcn_smoothed_d2ydx2(s))\n",
    "#     extra_none[-1] = np.array(extra_none[-1])\n",
    "# extra_none = np.array(extra_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_array(fold_ind, nim_fold):\n",
    "    # Generates an array of samples for training from within the training set. Recall that in this case,\n",
    "    # the order of samples loaded in the with statement below follows cvorder.\n",
    "    with open(os.path.join(destdir, subdir1, \n",
    "                       'SmoothedSamples_' + str(fold_ind) \n",
    "                       + '.p') , 'rb') as f:\n",
    "        train_array = pickle.load(f)\n",
    "    tr = []\n",
    "    tr_labs = []\n",
    "    for t_ind in range(len(train_array)):\n",
    "        if t_ind not in range(fold_ind * nim_fold, (fold_ind + 1) * nim_fold):\n",
    "            tr.extend(train_array[t_ind])\n",
    "            mark_ind, im_ind = fcn_mark_im_ind(cvorder[t_ind], 30)\n",
    "            if mark_ind == 2:\n",
    "                lab = 0\n",
    "            else:\n",
    "                lab = 1\n",
    "            tr_labs.extend([lab for _ in range(len(train_array[t_ind]))])\n",
    "    return tr, tr_labs, train_array\n",
    "\n",
    "def fcn_mark_im_ind(im_ind_raw, n_img):\n",
    "    \"\"\"\n",
    "    Calculates the mark an image index based on the total image index\n",
    "    For example, im_ind_raw is 52 and n_img is 30, then mark_ind is 1\n",
    "    and im_ind is 22\n",
    "    \"\"\"\n",
    "    mark_ind = int(im_ind_raw/n_img)\n",
    "    im_ind = im_ind_raw - mark_ind * n_img\n",
    "    return mark_ind, im_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently evaluating fold number 0\n",
      "Epoch 1/20\n",
      "3450/3450 [==============================] - 0s 43us/sample - loss: 0.4835 - acc: 0.8374\n",
      "Epoch 2/20\n",
      "3450/3450 [==============================] - 0s 30us/sample - loss: 0.2368 - acc: 0.9232\n",
      "Epoch 3/20\n",
      "3450/3450 [==============================] - 0s 29us/sample - loss: 0.1984 - acc: 0.9368\n",
      "Epoch 4/20\n",
      "3450/3450 [==============================] - 0s 29us/sample - loss: 0.1787 - acc: 0.9414\n",
      "Epoch 5/20\n",
      "3450/3450 [==============================] - 0s 29us/sample - loss: 0.1634 - acc: 0.9441\n",
      "Epoch 6/20\n",
      "3450/3450 [==============================] - 0s 31us/sample - loss: 0.1518 - acc: 0.9472\n",
      "Epoch 7/20\n",
      "3450/3450 [==============================] - 0s 32us/sample - loss: 0.1413 - acc: 0.9510\n",
      "Epoch 8/20\n",
      "3450/3450 [==============================] - 0s 30us/sample - loss: 0.1315 - acc: 0.9533\n",
      "Epoch 9/20\n",
      "3450/3450 [==============================] - 0s 31us/sample - loss: 0.1238 - acc: 0.9559\n",
      "Epoch 10/20\n",
      "3450/3450 [==============================] - 0s 33us/sample - loss: 0.1167 - acc: 0.9597\n",
      "Epoch 11/20\n",
      "3450/3450 [==============================] - 0s 35us/sample - loss: 0.1102 - acc: 0.9617\n",
      "Epoch 12/20\n",
      "3450/3450 [==============================] - 0s 37us/sample - loss: 0.1032 - acc: 0.9646\n",
      "Epoch 13/20\n",
      "3450/3450 [==============================] - 0s 36us/sample - loss: 0.0976 - acc: 0.9672\n",
      "Epoch 14/20\n",
      "3450/3450 [==============================] - 0s 33us/sample - loss: 0.0913 - acc: 0.9664\n",
      "Epoch 15/20\n",
      "3450/3450 [==============================] - 0s 32us/sample - loss: 0.0865 - acc: 0.9696\n",
      "Epoch 16/20\n",
      "3450/3450 [==============================] - 0s 32us/sample - loss: 0.0815 - acc: 0.9707\n",
      "Epoch 17/20\n",
      "3450/3450 [==============================] - 0s 31us/sample - loss: 0.0772 - acc: 0.9748\n",
      "Epoch 18/20\n",
      "3450/3450 [==============================] - 0s 30us/sample - loss: 0.0727 - acc: 0.9739\n",
      "Epoch 19/20\n",
      "3450/3450 [==============================] - 0s 31us/sample - loss: 0.0691 - acc: 0.9768\n",
      "Epoch 20/20\n",
      "3450/3450 [==============================] - 0s 32us/sample - loss: 0.0664 - acc: 0.9780\n",
      "check 1\n",
      "Currently evaluating fold number 1\n",
      "Epoch 1/20\n",
      "4392/4392 [==============================] - 0s 36us/sample - loss: 0.3613 - acc: 0.8652\n",
      "Epoch 2/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.1550 - acc: 0.9581\n",
      "Epoch 3/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.1123 - acc: 0.9727\n",
      "Epoch 4/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0892 - acc: 0.9791\n",
      "Epoch 5/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0732 - acc: 0.9829\n",
      "Epoch 6/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0607 - acc: 0.9854\n",
      "Epoch 7/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0506 - acc: 0.9872\n",
      "Epoch 8/20\n",
      "4392/4392 [==============================] - 0s 30us/sample - loss: 0.0425 - acc: 0.9900\n",
      "Epoch 9/20\n",
      "4392/4392 [==============================] - 0s 30us/sample - loss: 0.0360 - acc: 0.9907\n",
      "Epoch 10/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0308 - acc: 0.9925\n",
      "Epoch 11/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0253 - acc: 0.9941\n",
      "Epoch 12/20\n",
      "4392/4392 [==============================] - 0s 33us/sample - loss: 0.0220 - acc: 0.9948\n",
      "Epoch 13/20\n",
      "4392/4392 [==============================] - 0s 33us/sample - loss: 0.0191 - acc: 0.9961\n",
      "Epoch 14/20\n",
      "4392/4392 [==============================] - 0s 32us/sample - loss: 0.0165 - acc: 0.9966\n",
      "Epoch 15/20\n",
      "4392/4392 [==============================] - 0s 31us/sample - loss: 0.0150 - acc: 0.9966\n",
      "Epoch 16/20\n",
      "4392/4392 [==============================] - 0s 26us/sample - loss: 0.0126 - acc: 0.9975\n",
      "Epoch 17/20\n",
      "4392/4392 [==============================] - 0s 28us/sample - loss: 0.0108 - acc: 0.9973\n",
      "Epoch 18/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0094 - acc: 0.9982\n",
      "Epoch 19/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0079 - acc: 0.9984\n",
      "Epoch 20/20\n",
      "4392/4392 [==============================] - 0s 29us/sample - loss: 0.0072 - acc: 0.9984\n",
      "check 1\n",
      "Currently evaluating fold number 2\n",
      "Epoch 1/20\n",
      "6038/6038 [==============================] - 0s 35us/sample - loss: 0.2403 - acc: 0.9190\n",
      "Epoch 2/20\n",
      "6038/6038 [==============================] - 0s 26us/sample - loss: 0.1119 - acc: 0.9740\n",
      "Epoch 3/20\n",
      "6038/6038 [==============================] - 0s 26us/sample - loss: 0.0766 - acc: 0.9819\n",
      "Epoch 4/20\n",
      "6038/6038 [==============================] - 0s 26us/sample - loss: 0.0582 - acc: 0.9876\n",
      "Epoch 5/20\n",
      "6038/6038 [==============================] - 0s 26us/sample - loss: 0.0471 - acc: 0.9894\n",
      "Epoch 6/20\n",
      "6038/6038 [==============================] - 0s 27us/sample - loss: 0.0393 - acc: 0.9911\n",
      "Epoch 7/20\n",
      "6038/6038 [==============================] - 0s 27us/sample - loss: 0.0326 - acc: 0.9930\n",
      "Epoch 8/20\n",
      "6038/6038 [==============================] - 0s 27us/sample - loss: 0.0290 - acc: 0.9940\n",
      "Epoch 9/20\n",
      "6038/6038 [==============================] - 0s 26us/sample - loss: 0.0252 - acc: 0.9950\n",
      "Epoch 10/20\n",
      "6038/6038 [==============================] - 0s 27us/sample - loss: 0.0224 - acc: 0.9954\n",
      "Epoch 11/20\n",
      "6038/6038 [==============================] - 0s 27us/sample - loss: 0.0197 - acc: 0.9959\n",
      "Epoch 12/20\n",
      "6038/6038 [==============================] - 0s 28us/sample - loss: 0.0181 - acc: 0.9962\n",
      "Epoch 13/20\n",
      "6038/6038 [==============================] - 0s 29us/sample - loss: 0.0158 - acc: 0.9962\n",
      "Epoch 14/20\n",
      "6038/6038 [==============================] - 0s 28us/sample - loss: 0.0146 - acc: 0.9962\n",
      "Epoch 15/20\n",
      "6038/6038 [==============================] - 0s 29us/sample - loss: 0.0128 - acc: 0.9969\n",
      "Epoch 16/20\n",
      "6038/6038 [==============================] - 0s 28us/sample - loss: 0.0116 - acc: 0.9967\n",
      "Epoch 17/20\n",
      "6038/6038 [==============================] - 0s 29us/sample - loss: 0.0103 - acc: 0.9975\n",
      "Epoch 18/20\n",
      "6038/6038 [==============================] - 0s 29us/sample - loss: 0.0093 - acc: 0.9977\n",
      "Epoch 19/20\n",
      "6038/6038 [==============================] - 0s 29us/sample - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 20/20\n",
      "6038/6038 [==============================] - 0s 29us/sample - loss: 0.0073 - acc: 0.9985\n",
      "check 1\n",
      "Currently evaluating fold number 3\n",
      "Epoch 1/20\n",
      "2763/2763 [==============================] - 0s 48us/sample - loss: 0.6134 - acc: 0.7695\n",
      "Epoch 2/20\n",
      "2763/2763 [==============================] - 0s 25us/sample - loss: 0.2316 - acc: 0.9244\n",
      "Epoch 3/20\n",
      "2763/2763 [==============================] - 0s 27us/sample - loss: 0.1554 - acc: 0.9569\n",
      "Epoch 4/20\n",
      "2763/2763 [==============================] - 0s 26us/sample - loss: 0.1101 - acc: 0.9736\n",
      "Epoch 5/20\n",
      "2763/2763 [==============================] - 0s 27us/sample - loss: 0.0863 - acc: 0.9826\n",
      "Epoch 6/20\n",
      "2763/2763 [==============================] - 0s 26us/sample - loss: 0.0664 - acc: 0.9870\n",
      "Epoch 7/20\n",
      "2763/2763 [==============================] - 0s 28us/sample - loss: 0.0563 - acc: 0.9888\n",
      "Epoch 8/20\n",
      "2763/2763 [==============================] - 0s 26us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 9/20\n",
      "2763/2763 [==============================] - 0s 26us/sample - loss: 0.0363 - acc: 0.9928\n",
      "Epoch 10/20\n",
      "2763/2763 [==============================] - 0s 29us/sample - loss: 0.0308 - acc: 0.9942\n",
      "Epoch 11/20\n",
      "2763/2763 [==============================] - 0s 28us/sample - loss: 0.0263 - acc: 0.9942\n",
      "Epoch 12/20\n",
      "2763/2763 [==============================] - 0s 27us/sample - loss: 0.0228 - acc: 0.9949\n",
      "Epoch 13/20\n",
      "2763/2763 [==============================] - 0s 28us/sample - loss: 0.0198 - acc: 0.9960\n",
      "Epoch 14/20\n",
      "2763/2763 [==============================] - 0s 28us/sample - loss: 0.0174 - acc: 0.9967\n",
      "Epoch 15/20\n",
      "2763/2763 [==============================] - 0s 28us/sample - loss: 0.0154 - acc: 0.9975\n",
      "Epoch 16/20\n",
      "2763/2763 [==============================] - 0s 27us/sample - loss: 0.0135 - acc: 0.9975\n",
      "Epoch 17/20\n",
      "2763/2763 [==============================] - 0s 29us/sample - loss: 0.0122 - acc: 0.9975\n",
      "Epoch 18/20\n",
      "2763/2763 [==============================] - 0s 28us/sample - loss: 0.0106 - acc: 0.9978\n",
      "Epoch 19/20\n",
      "2763/2763 [==============================] - 0s 28us/sample - loss: 0.0096 - acc: 0.9978\n",
      "Epoch 20/20\n",
      "2763/2763 [==============================] - 0s 28us/sample - loss: 0.0083 - acc: 0.9982\n",
      "check 1\n",
      "Currently evaluating fold number 4\n",
      "Epoch 1/20\n",
      "3190/3190 [==============================] - 0s 51us/sample - loss: 0.4531 - acc: 0.8138\n",
      "Epoch 2/20\n",
      "3190/3190 [==============================] - 0s 29us/sample - loss: 0.2275 - acc: 0.9304\n",
      "Epoch 3/20\n",
      "3190/3190 [==============================] - 0s 30us/sample - loss: 0.1719 - acc: 0.9511\n",
      "Epoch 4/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.1340 - acc: 0.9621\n",
      "Epoch 5/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.1138 - acc: 0.9702\n",
      "Epoch 6/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0918 - acc: 0.9781\n",
      "Epoch 7/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0799 - acc: 0.9790\n",
      "Epoch 8/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0684 - acc: 0.9803\n",
      "Epoch 9/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0608 - acc: 0.9818\n",
      "Epoch 10/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0524 - acc: 0.9865\n",
      "Epoch 11/20\n",
      "3190/3190 [==============================] - 0s 32us/sample - loss: 0.0459 - acc: 0.9865\n",
      "Epoch 12/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0385 - acc: 0.9887\n",
      "Epoch 13/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0324 - acc: 0.9912\n",
      "Epoch 14/20\n",
      "3190/3190 [==============================] - 0s 30us/sample - loss: 0.0281 - acc: 0.9925\n",
      "Epoch 15/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0245 - acc: 0.9934\n",
      "Epoch 16/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0220 - acc: 0.9950\n",
      "Epoch 17/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0193 - acc: 0.9950\n",
      "Epoch 18/20\n",
      "3190/3190 [==============================] - 0s 30us/sample - loss: 0.0178 - acc: 0.9962\n",
      "Epoch 19/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0149 - acc: 0.9969\n",
      "Epoch 20/20\n",
      "3190/3190 [==============================] - 0s 31us/sample - loss: 0.0139 - acc: 0.9978\n",
      "check 1\n",
      "Currently evaluating fold number 5\n",
      "Epoch 1/20\n",
      "3469/3469 [==============================] - 0s 48us/sample - loss: 0.4274 - acc: 0.8285\n",
      "Epoch 2/20\n",
      "3469/3469 [==============================] - 0s 29us/sample - loss: 0.2284 - acc: 0.9268\n",
      "Epoch 3/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.1726 - acc: 0.9501\n",
      "Epoch 4/20\n",
      "3469/3469 [==============================] - 0s 29us/sample - loss: 0.1426 - acc: 0.9582\n",
      "Epoch 5/20\n",
      "3469/3469 [==============================] - 0s 29us/sample - loss: 0.1213 - acc: 0.9668\n",
      "Epoch 6/20\n",
      "3469/3469 [==============================] - 0s 29us/sample - loss: 0.1063 - acc: 0.9689\n",
      "Epoch 7/20\n",
      "3469/3469 [==============================] - 0s 29us/sample - loss: 0.0960 - acc: 0.9735\n",
      "Epoch 8/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0893 - acc: 0.9743\n",
      "Epoch 9/20\n",
      "3469/3469 [==============================] - 0s 29us/sample - loss: 0.0788 - acc: 0.9769\n",
      "Epoch 10/20\n",
      "3469/3469 [==============================] - 0s 29us/sample - loss: 0.0720 - acc: 0.9784\n",
      "Epoch 11/20\n",
      "3469/3469 [==============================] - 0s 29us/sample - loss: 0.0662 - acc: 0.9795\n",
      "Epoch 12/20\n",
      "3469/3469 [==============================] - 0s 31us/sample - loss: 0.0601 - acc: 0.9824\n",
      "Epoch 13/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0553 - acc: 0.9827\n",
      "Epoch 14/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0533 - acc: 0.9827\n",
      "Epoch 15/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0508 - acc: 0.9839\n",
      "Epoch 16/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0443 - acc: 0.9859\n",
      "Epoch 17/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0424 - acc: 0.9873\n",
      "Epoch 18/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0394 - acc: 0.9879\n",
      "Epoch 19/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0370 - acc: 0.9896\n",
      "Epoch 20/20\n",
      "3469/3469 [==============================] - 0s 30us/sample - loss: 0.0327 - acc: 0.9896\n",
      "check 1\n",
      "Currently evaluating fold number 6\n",
      "Epoch 1/20\n",
      "4642/4642 [==============================] - 0s 43us/sample - loss: 0.4140 - acc: 0.8132\n",
      "Epoch 2/20\n",
      "4642/4642 [==============================] - 0s 29us/sample - loss: 0.1770 - acc: 0.9425\n",
      "Epoch 3/20\n",
      "4642/4642 [==============================] - 0s 28us/sample - loss: 0.1093 - acc: 0.9694\n",
      "Epoch 4/20\n",
      "4642/4642 [==============================] - 0s 28us/sample - loss: 0.0728 - acc: 0.9830\n",
      "Epoch 5/20\n",
      "4642/4642 [==============================] - 0s 28us/sample - loss: 0.0503 - acc: 0.9892\n",
      "Epoch 6/20\n",
      "4642/4642 [==============================] - 0s 30us/sample - loss: 0.0357 - acc: 0.9922\n",
      "Epoch 7/20\n",
      "4642/4642 [==============================] - 0s 30us/sample - loss: 0.0263 - acc: 0.9950\n",
      "Epoch 8/20\n",
      "4642/4642 [==============================] - 0s 30us/sample - loss: 0.0202 - acc: 0.9968\n",
      "Epoch 9/20\n",
      "4642/4642 [==============================] - 0s 30us/sample - loss: 0.0146 - acc: 0.9974\n",
      "Epoch 10/20\n",
      "4642/4642 [==============================] - 0s 35us/sample - loss: 0.0111 - acc: 0.9985\n",
      "Epoch 11/20\n",
      "4642/4642 [==============================] - 0s 28us/sample - loss: 0.0085 - acc: 0.9989\n",
      "Epoch 12/20\n",
      "4642/4642 [==============================] - 0s 29us/sample - loss: 0.0067 - acc: 0.9996\n",
      "Epoch 13/20\n",
      "4642/4642 [==============================] - 0s 36us/sample - loss: 0.0054 - acc: 0.9996\n",
      "Epoch 14/20\n",
      "4642/4642 [==============================] - 0s 41us/sample - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "4642/4642 [==============================] - 0s 29us/sample - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "4642/4642 [==============================] - 0s 29us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "4642/4642 [==============================] - 0s 29us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "4642/4642 [==============================] - 0s 29us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "4642/4642 [==============================] - 0s 29us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "4642/4642 [==============================] - 0s 32us/sample - loss: 0.0015 - acc: 1.0000\n",
      "check 1\n",
      "Currently evaluating fold number 7\n",
      "Epoch 1/20\n",
      "3911/3911 [==============================] - 0s 49us/sample - loss: 0.3545 - acc: 0.8647\n",
      "Epoch 2/20\n",
      "3911/3911 [==============================] - 0s 29us/sample - loss: 0.1200 - acc: 0.9645\n",
      "Epoch 3/20\n",
      "3911/3911 [==============================] - 0s 28us/sample - loss: 0.0732 - acc: 0.9854\n",
      "Epoch 4/20\n",
      "3911/3911 [==============================] - 0s 28us/sample - loss: 0.0491 - acc: 0.9913\n",
      "Epoch 5/20\n",
      "3911/3911 [==============================] - 0s 28us/sample - loss: 0.0375 - acc: 0.9931\n",
      "Epoch 6/20\n",
      "3911/3911 [==============================] - 0s 33us/sample - loss: 0.0274 - acc: 0.9944\n",
      "Epoch 7/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0214 - acc: 0.9959\n",
      "Epoch 8/20\n",
      "3911/3911 [==============================] - 0s 33us/sample - loss: 0.0172 - acc: 0.9967\n",
      "Epoch 9/20\n",
      "3911/3911 [==============================] - 0s 33us/sample - loss: 0.0148 - acc: 0.9972\n",
      "Epoch 10/20\n",
      "3911/3911 [==============================] - 0s 33us/sample - loss: 0.0123 - acc: 0.9977\n",
      "Epoch 11/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0106 - acc: 0.9977\n",
      "Epoch 12/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0097 - acc: 0.9982\n",
      "Epoch 13/20\n",
      "3911/3911 [==============================] - 0s 33us/sample - loss: 0.0085 - acc: 0.9985\n",
      "Epoch 14/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0076 - acc: 0.9982\n",
      "Epoch 15/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0069 - acc: 0.9990\n",
      "Epoch 16/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0065 - acc: 0.9990\n",
      "Epoch 17/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0059 - acc: 0.9990\n",
      "Epoch 18/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0053 - acc: 0.9990\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0050 - acc: 0.9992\n",
      "Epoch 20/20\n",
      "3911/3911 [==============================] - 0s 32us/sample - loss: 0.0046 - acc: 0.9992\n",
      "check 1\n",
      "Currently evaluating fold number 8\n",
      "Epoch 1/20\n",
      "5367/5367 [==============================] - 0s 45us/sample - loss: 0.5088 - acc: 0.8127\n",
      "Epoch 2/20\n",
      "5367/5367 [==============================] - 0s 28us/sample - loss: 0.2127 - acc: 0.9324\n",
      "Epoch 3/20\n",
      "5367/5367 [==============================] - 0s 30us/sample - loss: 0.1562 - acc: 0.9503\n",
      "Epoch 4/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.1272 - acc: 0.9592\n",
      "Epoch 5/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.1062 - acc: 0.9646\n",
      "Epoch 6/20\n",
      "5367/5367 [==============================] - 0s 32us/sample - loss: 0.0903 - acc: 0.9702\n",
      "Epoch 7/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0788 - acc: 0.9735\n",
      "Epoch 8/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0693 - acc: 0.9771\n",
      "Epoch 9/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0614 - acc: 0.9801\n",
      "Epoch 10/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0539 - acc: 0.9821\n",
      "Epoch 11/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0474 - acc: 0.9845\n",
      "Epoch 12/20\n",
      "5367/5367 [==============================] - 0s 32us/sample - loss: 0.0431 - acc: 0.9858\n",
      "Epoch 13/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0380 - acc: 0.9877\n",
      "Epoch 14/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0337 - acc: 0.9898\n",
      "Epoch 15/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0306 - acc: 0.9899\n",
      "Epoch 16/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0271 - acc: 0.9920\n",
      "Epoch 17/20\n",
      "5367/5367 [==============================] - 0s 32us/sample - loss: 0.0247 - acc: 0.9937\n",
      "Epoch 18/20\n",
      "5367/5367 [==============================] - 0s 32us/sample - loss: 0.0220 - acc: 0.9946\n",
      "Epoch 19/20\n",
      "5367/5367 [==============================] - 0s 31us/sample - loss: 0.0202 - acc: 0.9946\n",
      "Epoch 20/20\n",
      "5367/5367 [==============================] - 0s 32us/sample - loss: 0.0185 - acc: 0.9950\n",
      "check 1\n",
      "Currently evaluating fold number 9\n",
      "Epoch 1/20\n",
      "4680/4680 [==============================] - 0s 50us/sample - loss: 0.4316 - acc: 0.8312\n",
      "Epoch 2/20\n",
      "4680/4680 [==============================] - 0s 31us/sample - loss: 0.1739 - acc: 0.9502\n",
      "Epoch 3/20\n",
      "4680/4680 [==============================] - 0s 34us/sample - loss: 0.1119 - acc: 0.9716\n",
      "Epoch 4/20\n",
      "4680/4680 [==============================] - 0s 33us/sample - loss: 0.0781 - acc: 0.9812\n",
      "Epoch 5/20\n",
      "4680/4680 [==============================] - 0s 34us/sample - loss: 0.0557 - acc: 0.9859\n",
      "Epoch 6/20\n",
      "4680/4680 [==============================] - 0s 33us/sample - loss: 0.0439 - acc: 0.9891\n",
      "Epoch 7/20\n",
      "4680/4680 [==============================] - 0s 33us/sample - loss: 0.0312 - acc: 0.9929\n",
      "Epoch 8/20\n",
      "4680/4680 [==============================] - 0s 33us/sample - loss: 0.0241 - acc: 0.9947\n",
      "Epoch 9/20\n",
      "4680/4680 [==============================] - 0s 34us/sample - loss: 0.0172 - acc: 0.9974\n",
      "Epoch 10/20\n",
      "4680/4680 [==============================] - 0s 32us/sample - loss: 0.0134 - acc: 0.9981\n",
      "Epoch 11/20\n",
      "4680/4680 [==============================] - 0s 32us/sample - loss: 0.0104 - acc: 0.9989\n",
      "Epoch 12/20\n",
      "4680/4680 [==============================] - 0s 34us/sample - loss: 0.0086 - acc: 0.9987\n",
      "Epoch 13/20\n",
      "4680/4680 [==============================] - 0s 32us/sample - loss: 0.0067 - acc: 0.9989\n",
      "Epoch 14/20\n",
      "4680/4680 [==============================] - 0s 33us/sample - loss: 0.0073 - acc: 0.9983\n",
      "Epoch 15/20\n",
      "4680/4680 [==============================] - 0s 33us/sample - loss: 0.0111 - acc: 0.9972\n",
      "Epoch 16/20\n",
      "4680/4680 [==============================] - 0s 34us/sample - loss: 0.0043 - acc: 0.9996\n",
      "Epoch 17/20\n",
      "4680/4680 [==============================] - 0s 32us/sample - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 18/20\n",
      "4680/4680 [==============================] - 0s 33us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "4680/4680 [==============================] - 0s 33us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "4680/4680 [==============================] - 0s 32us/sample - loss: 0.0020 - acc: 1.0000\n",
      "check 1\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "yhat = []\n",
    "save_scores = []\n",
    "fmod_name_base = 'BinaryNetworks/binarynet_'\n",
    "for fold_ind in range(10):\n",
    "    print(\"Currently evaluating fold number {}\".format(fold_ind))\n",
    "    mod = keras.models.load_model(fmod_name_base + str(fold_ind) + '.h5', compile=False)\n",
    "    temp_model = make_transfer_module(mod)\n",
    "    tr, tr_labs, train_array = make_train_array(fold_ind, nim_fold)\n",
    "    while np.mean(tr_labs) > 0.5:\n",
    "        none_im_ind = np.random.randint(0, 30)\n",
    "        while none_im_ind + 60 in cvorder[fold_ind * nim_fold:(fold_ind + 1) * nim_fold]:\n",
    "            none_im_ind = np.random.randint(0, 30)\n",
    "        tr_ind = np.where(cvorder==none_im_ind + 60)[0][0]\n",
    "        tr.extend(train_array[tr_ind])\n",
    "        tr_labs.extend([ 0 for _ in range(len(train_array[tr_ind]))])\n",
    "    tr = np.array(tr)\n",
    "    tr_labs = np.array(tr_labs, dtype=int)\n",
    "    tr_2 = temp_model.predict(np.expand_dims(tr, axis=2))\n",
    "    nm_model = make_none_marked_model()\n",
    "    nm_model.fit(np.expand_dims(tr_2, axis=2), tr_labs, epochs=20)\n",
    "    print('check 1')\n",
    "    for ind in range(fold_ind * nim_fold, (fold_ind + 1) * nim_fold):\n",
    "        samps = train_array[ind]\n",
    "        samps_2 = temp_model.predict(np.expand_dims(samps, axis=2))\n",
    "        mark_ind, im_ind = fcn_mark_im_ind(cvorder[ind], 30)\n",
    "        if mark_ind == 2:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "        scores = np.mean(nm_model.predict(samps_2), axis=0)\n",
    "        save_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary accuracy at expected optimal cutoff: 0.947\n"
     ]
    }
   ],
   "source": [
    "yhat = []\n",
    "for s in save_scores:\n",
    "    if s[0] > 0.29:\n",
    "        yhat.append(0)\n",
    "    else:\n",
    "        yhat.append(1)\n",
    "acc = np.sum(np.array(yhat)==np.array(y))/len(yhat)\n",
    "print('Binary accuracy at expected optimal cutoff: {:0.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall classification accuracy: 0.927\n"
     ]
    }
   ],
   "source": [
    "scbase = 'ClassifierSampleSelectionCombined/Scores/Scores_'\n",
    "yhatclass = np.ones(150, dtype=int) * -1\n",
    "yhatfin = np.ones(150, dtype=int) * 2\n",
    "yfin = np.ones(150, dtype=int) * -1\n",
    "for fold_ind in range(10):\n",
    "    with open(scbase + str(fold_ind) + '.p', 'rb') as f:\n",
    "        sc = pickle.load(f)\n",
    "    for ind in range(nim_fold * fold_ind, (fold_ind + 1) * nim_fold):\n",
    "        mark, im_ind = fcn_mark_im_ind(cvorder[ind], 30)\n",
    "        sctemp = np.average(sc[ind], axis=0)\n",
    "        yhatclass[ind] = np.argmax(sctemp)\n",
    "        if yhat[ind] != 0:\n",
    "            yhatfin[ind] = yhatclass[ind] \n",
    "        yfin[ind] = mark\n",
    "print('Overall classification accuracy: {:0.3f}'.format(np.sum(yhatfin==yfin) / len(yfin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marked classification accuracy: 0.917\n",
      "Unmarked classification accuracy: 0.967\n",
      "Marked classification accuracy before binary filter: 0.950\n",
      "Marked binary accuracy: 0.942\n"
     ]
    }
   ],
   "source": [
    "cond = yfin != 2\n",
    "print('marked classification accuracy: {:0.3f}'.\n",
    "      format(np.sum(yfin[cond] == yhatfin[cond]) / np.sum(cond)))\n",
    "icond = np.invert(cond)\n",
    "print('Unmarked classification accuracy: {:0.3f}'.\n",
    "      format(np.sum(yfin[icond] == yhatfin[icond]) / np.sum(icond)))\n",
    "print(\"Marked classification accuracy before binary filter: {:0.3f}\".\n",
    "     format(np.sum(yhatclass[cond] == yfin[cond]) / np.sum(cond)))\n",
    "print(\"Marked binary accuracy: {:0.3f}\".\n",
    "     format(np.sum(np.array(yhat)[cond] == 1) / np.sum(cond)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff: 0.1, binary accuracy: 0.753\n",
      "Cutoff: 0.2, binary accuracy: 0.900\n",
      "Cutoff: 0.3, binary accuracy: 0.953\n",
      "Cutoff: 0.4, binary accuracy: 0.953\n",
      "Cutoff: 0.5, binary accuracy: 0.920\n",
      "Cutoff: 0.6, binary accuracy: 0.900\n",
      "Cutoff: 0.7, binary accuracy: 0.873\n",
      "Cutoff: 0.8, binary accuracy: 0.833\n",
      "Cutoff: 0.9, binary accuracy: 0.813\n"
     ]
    }
   ],
   "source": [
    "for cutoff in np.linspace(0.1, 0.9, 9):\n",
    "    yhat = []\n",
    "    for s in save_scores:\n",
    "        if s[0] > cutoff:\n",
    "            yhat.append(0)\n",
    "        else:\n",
    "            yhat.append(1)\n",
    "    yhat = np.array(yhat)\n",
    "    print(\"Cutoff: {:0.1f}, binary accuracy: {:0.3f}\".format(cutoff, np.sum(yhat==y)/len(yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(100, 0.927)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1159\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(10000):\n",
    "    res.append(np.random.binomial(100, 0.927))\n",
    "print(np.sum(np.array(res) <= 89) / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
