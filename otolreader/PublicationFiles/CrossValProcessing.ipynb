{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size'   : 14}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import OtolReader as otolr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '../../OtolReader-Publication/Models'\n",
    "with open(os.path.join(basedir, 'crossval_order.p'), 'rb') as f:\n",
    "    cvorder = np.array(pickle.load(f))\n",
    "pdir = os.path.join(basedir, 'CrossVal-Binary-5classes-30Images')\n",
    "model_prefix = 'binarynet_'\n",
    "nim_fold = 15\n",
    "sampledir = os.path.join(basedir, 'CrossVal-ClassifierSampleTable')\n",
    "samps_prefix = 'ClassifierNetworkForSelection_SmoothedSamples_'\n",
    "retrained_dir = os.path.join(basedir, 'Retrained-Binary-Nets')\n",
    "classmod_name_base = os.path.join(basedir, 'CrossVal-Classifier-5classes-30Images', 'classnet_')\n",
    "imdir = '../../Images/OtolithImages/'\n",
    "mark_list = ['3,5H10', '1,6H', 'none', '6,2H', '4n,2n,2H']\n",
    "fmod_name_base = os.path.join(retrained_dir, 'binarynet_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_scores = []\n",
    "y = []\n",
    "for fold_ind in range(10):\n",
    "    with open(os.path.join(sampledir, samps_prefix + str(fold_ind) + '.p'), 'rb') as f:\n",
    "        train_array = pickle.load(f)\n",
    "    nm_model = keras.models.load_model(fmod_name_base + str(fold_ind) + '.h5', compile=False)\n",
    "    for ind in range(fold_ind * nim_fold, (fold_ind + 1) * nim_fold):\n",
    "        samps = train_array[ind]\n",
    "        mark_ind, im_ind = otolr.OtolithAnalysis.feature_functions.fcn_mark_im_ind(cvorder[ind], 30)\n",
    "        if mark_ind == 2:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "        scores = np.mean(nm_model.predict(np.expand_dims(samps, axis=2)), axis=0)\n",
    "        save_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary accuracy at expected optimal cutoff: 0.987\n"
     ]
    }
   ],
   "source": [
    "yhat = []\n",
    "for s in save_scores:\n",
    "    if s[0] > 0.2:\n",
    "        yhat.append(0)\n",
    "    else:\n",
    "        yhat.append(1)\n",
    "acc = np.sum(np.array(yhat)==np.array(y))/len(yhat)\n",
    "print('Binary accuracy at expected optimal cutoff: {:0.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall classification accuracy: 0.953\n"
     ]
    }
   ],
   "source": [
    "scbase = os.path.join(basedir, 'CrossVal-ClassifierSampleTable', 'ClassifierNetworkForSelection_Scores_')\n",
    "yhatclass = np.ones(150, dtype=int) * -1\n",
    "yhatfin = np.ones(150, dtype=int) * 2\n",
    "yfin = np.ones(150, dtype=int) * -1\n",
    "for fold_ind in range(10):\n",
    "    with open(scbase + str(fold_ind) + '.p', 'rb') as f:\n",
    "        sc = pickle.load(f)\n",
    "    for ind in range(nim_fold * fold_ind, (fold_ind + 1) * nim_fold):\n",
    "        mark, im_ind = otolr.OtolithAnalysis.feature_functions.fcn_mark_im_ind(cvorder[ind], 30)\n",
    "        sctemp = np.average(sc[ind], axis=0)\n",
    "        yhatclass[ind] = np.argmax(sctemp)\n",
    "        if yhat[ind] != 0:\n",
    "            yhatfin[ind] = yhatclass[ind] \n",
    "        yfin[ind] = mark\n",
    "print('Overall classification accuracy: {:0.3f}'.format(np.sum(yhatfin==yfin) / len(yfin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.  1.  0.  0.  1.]\n",
      " [ 0. 29.  1.  0.  0.]\n",
      " [ 0.  0. 30.  0.  0.]\n",
      " [ 0.  0.  1. 29.  0.]\n",
      " [ 1.  2.  0.  0. 27.]]\n"
     ]
    }
   ],
   "source": [
    "conf = np.zeros([5, 5])\n",
    "for ind in range(len(yfin)):\n",
    "    conf[yfin[ind], yhatfin[ind]] += 1\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating image #14\n",
      "Expected mark: 3,5H10\n",
      "Estimated mark: 3,5H10\n"
     ]
    }
   ],
   "source": [
    "# test the image classfication function\n",
    "nm_model = keras.models.load_model(fmod_name_base + str(0) + '.h5', compile=False)\n",
    "class_model = keras.models.load_model(classmod_name_base + str(0) + '.h5', compile=False)\n",
    "im_ind = cvorder[0]\n",
    "print(\"Evaluating image #{:0.0f}\".format(im_ind))\n",
    "mark_ind, classed_im_ind = otolr.OtolithAnalysis.feature_functions.fcn_mark_im_ind(im_ind, 30)\n",
    "print(\"Expected mark: {}\".format(mark_list[mark_ind]))\n",
    "im_path = os.path.join(imdir, mark_list[mark_ind], str(classed_im_ind) + '.jpg')\n",
    "mark_hat = otolr.OtolithAnalysis.im_classifier.classify_image(im_path, class_model, nm_model, 0.2)\n",
    "print(\"Estimated mark: {}\".format(mark_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '../../Network classifier/TwoNetworkTesting/FullTrainingSetModels'\n",
    "dir0 = 'ClassifierSampleSelection'\n",
    "subdir1 = 'Samples'\n",
    "subdir2 = 'Scores'\n",
    "subdir3 = 'Score_Tables'\n",
    "dir1 = 'ClassifierSampleSelection50'\n",
    "pstr = '2019_08_18_ClassifierNetworkForSelection_'\n",
    "destdir = 'ClassifierSampleSelectionCombined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(basedir, '2019_08_26_ClassifierNetworkForSelection_SmoothedSamples_0.p')\n",
    "test_path = os.path.join(basedir, 'TestSetSamples/2019_08_26_ClassifierNetworkForSelection_SmoothedSamples_0.p')\n",
    "def make_train_array(samp_path):\n",
    "    with open(samp_path, 'rb') as f:\n",
    "        train_array = pickle.load(f)\n",
    "    tr = []\n",
    "    tr_labs = []\n",
    "    for t_ind in range(len(train_array)):\n",
    "        tr.extend(train_array[t_ind])\n",
    "        mark_ind, im_ind = fcn_mark_im_ind(t_ind, 30)\n",
    "        if mark_ind == 2:\n",
    "            lab = 0\n",
    "        else:\n",
    "            lab = 1\n",
    "        tr_labs.extend([lab for _ in range(len(train_array[t_ind]))])\n",
    "    return tr, tr_labs, train_array\n",
    "\n",
    "def fcn_mark_im_ind(im_ind_raw, n_img):\n",
    "    \"\"\"\n",
    "    Calculates the mark an image index based on the total image index\n",
    "    For example, im_ind_raw is 52 and n_img is 30, then mark_ind is 1\n",
    "    and im_ind is 22\n",
    "    \"\"\"\n",
    "    mark_ind = int(im_ind_raw/n_img)\n",
    "    im_ind = im_ind_raw - mark_ind * n_img\n",
    "    return mark_ind, im_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently evaluating fold number fulltraining\n",
      "Train on 5822 samples\n",
      "Epoch 1/20\n",
      "5822/5822 [==============================] - 1s 94us/sample - loss: 0.4237 - accuracy: 0.8451\n",
      "Epoch 2/20\n",
      "5822/5822 [==============================] - 0s 46us/sample - loss: 0.1662 - accuracy: 0.9589\n",
      "Epoch 3/20\n",
      "5822/5822 [==============================] - 0s 47us/sample - loss: 0.1078 - accuracy: 0.9729\n",
      "Epoch 4/20\n",
      "5822/5822 [==============================] - 0s 48us/sample - loss: 0.0761 - accuracy: 0.9813\n",
      "Epoch 5/20\n",
      "5822/5822 [==============================] - 0s 50us/sample - loss: 0.0565 - accuracy: 0.9856\n",
      "Epoch 6/20\n",
      "5822/5822 [==============================] - 0s 49us/sample - loss: 0.0438 - accuracy: 0.9894\n",
      "Epoch 7/20\n",
      "5822/5822 [==============================] - 0s 50us/sample - loss: 0.0347 - accuracy: 0.9923\n",
      "Epoch 8/20\n",
      "5822/5822 [==============================] - 0s 47us/sample - loss: 0.0289 - accuracy: 0.9935\n",
      "Epoch 9/20\n",
      "5822/5822 [==============================] - 0s 50us/sample - loss: 0.0234 - accuracy: 0.9947\n",
      "Epoch 10/20\n",
      "5822/5822 [==============================] - 0s 51us/sample - loss: 0.0192 - accuracy: 0.9952\n",
      "Epoch 11/20\n",
      "5822/5822 [==============================] - 0s 51us/sample - loss: 0.0161 - accuracy: 0.9962\n",
      "Epoch 12/20\n",
      "5822/5822 [==============================] - 0s 48us/sample - loss: 0.0136 - accuracy: 0.9966\n",
      "Epoch 13/20\n",
      "5822/5822 [==============================] - 0s 45us/sample - loss: 0.0115 - accuracy: 0.9971\n",
      "Epoch 14/20\n",
      "5822/5822 [==============================] - 0s 45us/sample - loss: 0.0095 - accuracy: 0.9979\n",
      "Epoch 15/20\n",
      "5822/5822 [==============================] - 0s 46us/sample - loss: 0.0082 - accuracy: 0.9981\n",
      "Epoch 16/20\n",
      "5822/5822 [==============================] - 0s 49us/sample - loss: 0.0066 - accuracy: 0.9986\n",
      "Epoch 17/20\n",
      "5822/5822 [==============================] - 0s 52us/sample - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 18/20\n",
      "5822/5822 [==============================] - 0s 49us/sample - loss: 0.0047 - accuracy: 0.9995\n",
      "Epoch 19/20\n",
      "5822/5822 [==============================] - 0s 48us/sample - loss: 0.0041 - accuracy: 0.9997\n",
      "Epoch 20/20\n",
      "5822/5822 [==============================] - 0s 49us/sample - loss: 0.0033 - accuracy: 0.9997\n",
      "check 1\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "yhat = []\n",
    "save_scores = []\n",
    "fmod_name_base = os.path.join(basedir, 'binarynet_')\n",
    "print(\"Currently evaluating fold number {}\".format('fulltraining'))\n",
    "mod = keras.models.load_model(fmod_name_base + 'fulltraining.h5', compile=False)\n",
    "temp_model = make_transfer_module(mod)\n",
    "tr, tr_labs, train_array = make_train_array(train_path)\n",
    "while np.mean(tr_labs) > 0.5:\n",
    "    none_im_ind = np.random.randint(0, 30)\n",
    "    tr_ind = none_im_ind + 60\n",
    "    tr.extend(train_array[tr_ind])\n",
    "    tr_labs.extend([ 0 for _ in range(len(train_array[tr_ind]))])\n",
    "tr = np.array(tr)\n",
    "tr_labs = np.array(tr_labs, dtype=int)\n",
    "tr_2 = temp_model.predict(np.expand_dims(tr, axis=2))\n",
    "nm_model = make_none_marked_model()\n",
    "nm_model.fit(np.expand_dims(tr_2, axis=2), tr_labs, epochs=20)\n",
    "print('check 1')\n",
    "_, _, test_array = make_train_array(test_path)\n",
    "for ind in range(len(test_array)):\n",
    "    samps = test_array[ind]\n",
    "    samps_2 = temp_model.predict(np.expand_dims(samps, axis=2))\n",
    "    mark_ind, im_ind = fcn_mark_im_ind(ind, 20)\n",
    "    if mark_ind == 2:\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)\n",
    "    scores = np.mean(nm_model.predict(samps_2), axis=0)\n",
    "    save_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666666666666"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "139/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary accuracy at expected optimal cutoff: 0.950\n"
     ]
    }
   ],
   "source": [
    "yhat = []\n",
    "for s in save_scores:\n",
    "    if s[0] > 0.29:\n",
    "        yhat.append(0)\n",
    "    else:\n",
    "        yhat.append(1)\n",
    "acc = np.sum(np.array(yhat)==np.array(y))/len(yhat)\n",
    "print('Binary accuracy at expected optimal cutoff: {:0.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall classification accuracy: 0.900\n"
     ]
    }
   ],
   "source": [
    "scpath = os.path.join(basedir, 'TestSetSamples/2019_08_26_ClassifierNetworkForSelection_Scores_0.p')\n",
    "yhatclass = np.ones(100, dtype=int) * -1\n",
    "yhatfin = np.ones(100, dtype=int) * 2\n",
    "yfin = np.ones(100, dtype=int) * -1\n",
    "with open(scpath, 'rb') as f:\n",
    "    sc = pickle.load(f)\n",
    "for ind in range(100):\n",
    "    mark, im_ind = fcn_mark_im_ind(ind, 20)\n",
    "    sctemp = np.average(sc[ind], axis=0)\n",
    "    yhatclass[ind] = np.argmax(sctemp)\n",
    "    if yhat[ind] != 0:\n",
    "        yhatfin[ind] = yhatclass[ind] \n",
    "    yfin[ind] = mark\n",
    "print('Overall classification accuracy: {:0.3f}'.format(np.sum(yhatfin==yfin) / len(yfin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.  0.  2.  1.  0.]\n",
      " [ 0. 17.  0.  1.  2.]\n",
      " [ 0.  0. 20.  0.  0.]\n",
      " [ 0.  0.  1. 18.  1.]\n",
      " [ 0.  0.  2.  0. 18.]]\n"
     ]
    }
   ],
   "source": [
    "conf = np.zeros([5, 5])\n",
    "for ind in range(len(yfin)):\n",
    "    conf[yfin[ind], yhatfin[ind]] += 1\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smd2ydx2 = oa.finder_network.fcn_smoothed_d2ydx2(samp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.expand_dims(np.expand_dims(smd2ydx2, axis=0), axis=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
